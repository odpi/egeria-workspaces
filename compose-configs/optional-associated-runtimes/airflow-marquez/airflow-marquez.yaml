# SPDX-License-Identifier: Apache-2.0
# Optimized for Airflow 3.1.7 | Toggleable OpenLineage (Marquez vs. Marquez+Egeria)
name: airflow-marquez

x-airflow-common: &airflow-common
  build: .
  image: airflow-egeria:3.1.7
  user: "${AIRFLOW_UID:-50000}:0"
  env_file:
    - .env
    - openlineage.env
  environment: &airflow-common-env
    AIRFLOW_UID: "50000"
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow_user:${AIRFLOW_DATABASE_PASSWORD}@host.docker.internal:5442/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow_user:${AIRFLOW_DATABASE_PASSWORD}@host.docker.internal:5442/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://airflow-apiserver:8072/execution/'

    # --- OPENLINEAGE TOGGLE LOGIC ---
    AIRFLOW__OPENLINEAGE__DISABLED: 'false'
    AIRFLOW__OPENLINEAGE__NAMESPACE: 'egeria-workspace'
    AIRFLOW__OPENLINEAGE__TRANSPORT: '${OL_TRANSPORT:-{"type": "http", "url": "http://marquez:5050", "endpoint": "api/v1/lineage"}}'

    AIRFLOW__API__PORT: "8072"

  volumes:
    - ${AIRFLOW_PROJ_DIR:-./runtime-data}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-./runtime-data}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-./runtime-data}/plugins:/opt/airflow/plugins
  networks:
    - egeria_network

services:
  redis:
    image: redis:7.2-bookworm
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always
    networks:
      - egeria_network

  airflow-apiserver:
    <<: *airflow-common
    command: api-server
    ports:
      - "8072:8072"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8072/api/v2/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    healthcheck:
      test: ["CMD-SHELL", 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-apiserver:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -v -p /opt/airflow/{logs,dags,plugins,config}
        chown -v -R "${AIRFLOW_UID:-50000}:0" /opt/airflow/{logs,dags,plugins,config}
        /entrypoint airflow db migrate
        /entrypoint airflow fab users create --username airflow --password airflow --role Admin --firstname Airflow --lastname Admin --email airflow@example.com || true
        /entrypoint airflow version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    user: "0:0"

  marquez:
    image: marquezproject/marquez:latest
    platform: linux/amd64
    env_file:
      - .env
    ports:
      - "5050:5050"
      - "5051:5051"
    environment:
      - MARQUEZ_PORT=5050
      - MARQUEZ_ADMIN_PORT=5051
      - MARQUEZ_CONFIG=/usr/src/app/marquez.yml
      - POSTGRES_HOST=host.docker.internal
      - POSTGRES_PORT=5442
      - POSTGRES_DB=marquez
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - SEARCH_ENABLED=false
    volumes:
      - ./marquez.yml:/usr/src/app/marquez.yml
    networks:
      - egeria_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5051/healthcheck"]
      interval: 10s

  marquez-web:
    image: marquezproject/marquez-web:latest
    platform: linux/amd64
    ports:
      - "3000:3000"
    environment:
      - WEB_PORT=3000
      - MARQUEZ_HOST=marquez
      - MARQUEZ_PORT=5050
    networks:
      - egeria_network
    depends_on:
      marquez:
        condition: service_healthy

networks:
  egeria_network:
    name: egeria_network
    external: true
